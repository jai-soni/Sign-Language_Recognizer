{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Key number:  27\n",
      "Escape hit, closing...\n"
     ]
    }
   ],
   "source": [
    "# Here is a simple program that displays the camera feed in a cv2.namedWindow and will save images inside bounding box when 'c' is pressed on keyboard. \n",
    "# It will also quit if you hit ESC.\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "from keras.models import load_model, model_from_json\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# dimensions of our images\n",
    "image_x, image_y = 64, 64\n",
    "\n",
    "cam = cv2.VideoCapture(1)\n",
    "if cam.read()[0]==False:\n",
    "    cam = cv2.VideoCapture(0)\n",
    "#Prediction Classes\n",
    "gesture_list = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','OK GOOGLE','P','Q','R','S','SPACE','T','U','V','W','X','Y','Z']\n",
    "\n",
    "def get_bounding_box(img):\n",
    "    x, y, w, h = 420, 140, 200, 200\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,0), 3)\n",
    "    \n",
    "def get_cropped_image(img):\n",
    "    x, y, w, h = 420, 140, 200, 200\n",
    "#     cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,0), 3)\n",
    "    imgCrop = img[y:y+h, x:x+w]\n",
    "    return imgCrop\n",
    "\n",
    "def process_image(img):\n",
    "    # clone the frame\n",
    "    clone = img.copy()\n",
    "    # convert to grayscale\n",
    "    grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # applying gaussian blur\n",
    "    value = (35, 35)\n",
    "    blurred = cv2.GaussianBlur(grey, value, 0)\n",
    "\n",
    "    # thresholdin: Otsu's Binarization method\n",
    "    _, thresh = cv2.threshold(blurred, 127, 255,\n",
    "                               cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    return thresh\n",
    "def load_new_model():\n",
    "    # load json and create model\n",
    "    json_file = open('model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"model.h5\")\n",
    "    print(\"Loaded model from disk\")\n",
    "    return loaded_model\n",
    "\n",
    "def get_prediction(img,loaded_model):\n",
    "    loaded_model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    \n",
    "    images = np.vstack([x])\n",
    "    classes = loaded_model.predict_classes(images, batch_size=10)\n",
    "    prediction = gesture_list[int(classes)]\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "def start_camera(loaded_model):\n",
    "    frames=0\n",
    "    sentence = \"\"\n",
    "    while True:\n",
    "        img = cam.read()[1]\n",
    "        img = cv2.flip(img, 1)\n",
    "        img_cropped = get_cropped_image(img)\n",
    "        processed_img = process_image(img_cropped)\n",
    "        # Convert to image with 3 Channels\n",
    "        thresh = cv2.cvtColor(processed_img, cv2.COLOR_GRAY2RGB)\n",
    "        # make a PIL image\n",
    "        to_predict = Image.fromarray(thresh)\n",
    "        to_predict = to_predict.resize((64,64))\n",
    "        contours = cv2.findContours(processed_img.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)[1]\n",
    "        contour = max(contours, key = cv2.contourArea)\n",
    "        img_name= \"gesture.jpg\"\n",
    "        if len(contours) > 0:\n",
    "            if cv2.contourArea(contour) < 10000 and frames > 50:\n",
    "                try:\n",
    "#                     pred = get_prediction(to_predict,loaded_model)\n",
    "#                     if pred ==\"SPACE\":\n",
    "#                         sentence = sentence + \" \"\n",
    "#                     elif pred ==\"OK GOOGLE\":\n",
    "#                         pass\n",
    "#                     else:\n",
    "#                         sentence = sentence + pred\n",
    "#                     cv2.putText(img, pred, (30, 60), cv2.FONT_HERSHEY_TRIPLEX, 2, (127, 255, 255))\n",
    "#                     cv2.putText(img, sentence, (30, 400), cv2.FONT_HERSHEY_TRIPLEX, 0.7, (127, 127, 255))\n",
    "                    cv2.imwrite(img_name, thresh)\n",
    "                except Exception as e:\n",
    "                    pred = \"--\"\n",
    "                    print(\"Something Happened :\",e)\n",
    "                    break\n",
    "        else:\n",
    "            print(\"Cannot Recognize Hand Moments-Too much disturbance! Get a Plain Background with Hand Gestures on Front\")\n",
    "        get_bounding_box(img)\n",
    "        cv2.putText(processed_img, str(cv2.contourArea(contour)), (30, 400), cv2.FONT_HERSHEY_TRIPLEX, 0.7, (127, 127, 255))\n",
    "        cv2.imshow(\"Capturing gesture\", img)\n",
    "        cv2.imshow(\"thresh\", processed_img)\n",
    "        keypress = cv2.waitKey(1)\n",
    "        if not keypress==-1:\n",
    "            print(\"Key number: \",keypress)\n",
    "        if keypress%256 == 27:\n",
    "            # 'ESC' pressed\n",
    "            print(\"Escape hit, closing...\")\n",
    "            break\n",
    "        frames +=1\n",
    "\n",
    "loaded_model = load_new_model()\n",
    "try:\n",
    "    start_camera(loaded_model)\n",
    "except Exception as e:\n",
    "    print(\"Something Happened :\",e)\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_image(img):\n",
    "    # clone the frame\n",
    "    clone = img.copy()\n",
    "    # convert to grayscale\n",
    "    grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # applying gaussian blur\n",
    "    value = (35, 35)\n",
    "    blurred = cv2.GaussianBlur(grey, value, 0)\n",
    "\n",
    "    # thresholdin: Otsu's Binarization method\n",
    "    _, thresh = cv2.threshold(blurred, 127, 255,\n",
    "                               cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    return thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Key number:  27\n",
      "Escape hit, closing...\n"
     ]
    }
   ],
   "source": [
    "#Basic CV2 function to read camera input\n",
    "import cv2\n",
    "from PIL import Image\n",
    "cam = cv2.VideoCapture(1)\n",
    "load_new_model()\n",
    "if cam.read()[0]==False:\n",
    "    cam = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    img = cam.read()[1]\n",
    "    img = cv2.flip(img, 1)\n",
    "    img_cropped = get_cropped_image(img)\n",
    "    thresh = process_image(img_cropped)\n",
    "    # Convert to image with 3 Channels\n",
    "    thresh2 = cv2.cvtColor(thresh, cv2.COLOR_GRAY2RGB)\n",
    "    img2 = Image.fromarray(thresh2, 'RGB')\n",
    "    get_bounding_box(img)\n",
    "    cv2.imshow(\"Capturing gesture\", img)\n",
    "    cv2.imshow(\"Cropped\", img_cropped)\n",
    "    cv2.imshow(\"Threshold\",thresh)\n",
    "    keypress = cv2.waitKey(1)\n",
    "    if not keypress==-1:\n",
    "        print(\"Key number: \",keypress)\n",
    "    if keypress%256 == 27:\n",
    "        # 'ESC' pressed\n",
    "        print(\"Escape hit, closing...\")\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAIAAAAiOjnJAAAEQ0lEQVR4nO3cW5LiQAxEUffsf8/MhyPcBA3Gj5IqU7pnA4NL1+LRMMsCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIMDj8Zj9EBDlJ/nf24/p5yf78SBI6iBPrSgis5Y3vClPfNQ5S9K5i7ycorM0xTfWJxQWTfc1VgLyijPnZKUKI68Ik89UpzDyGkvlNEUKI69R5M6RwmrQPT4Ks6Z+aiJ5LRR2ksdhkZcdm2PSaWshrwPMDoi8XPyb/QDOkZqlVOVqhOZ0nNpEpXIXYbaxVmqDVAtdgdaEThEcp1rxE1lurJXgFAVbn0VuNmdpzlIw+mQVrl+zraV3XkWuXLatpWtexq+xnikPTzn6OLrzuEZ5isr1D1fwUpXbWtrkVfMixdtaGuRV5DXWC/2x6ad/k/oA7rAYnv49cE3NjbWymJlF/RcYHP1NLpOzuA2Oq7yxVi4Dc7kBDqof1kJbM7QIa6GtdB7HPYrR2FzuhE+6bKyV0bSM7oG3eoW10FYWm1Mey2tmRjfDpt3GWnmNyus2WDmd73B2AzO6H5puLFNGd4LNHRDEaFTP9FcXG8vS4/EQvyUIy5hyXt3D0n9O+Uqzre5h1SC4ugirDqm2CKsUndVFWAUptEVYNU1vi7AqvDF8a25bhFXZxLYIq7hZbRFWfVPaIqwW8tsirC6S2yIshCCs+R/5pMm8UsLqJa0twmonp63uYfV5HnyWcNXdw2oruq3WYfVcV5vQy28dFuLa0vrD/vHrvPmVhOa76kXE9zvmhzVqxsdPh6r+Gt7WtLCip/v3pOhp39i2JoTFgJWNyis1LJKyMKStvHeFVOViyKSSNhZVObqzujI2FlWZujM4PiDFnsu/gCUsfHehrYywqv5wr5WzbbGxcNSpp8WksFhaZRxsK3vevEMsY39ZZD8VsrrK2N8RZf8IjTRvl8Xk/UFeZbzkpfLERGE1bHmphLUirzK0wtpQmDvRsDYUZko9rA2FebEJ6xmR6bMMa0NhsrzD2lCYmiJhbShMRLWwNhQ2V9mwVuQ1S/GwNhSWrEtYK/JK0yusDYVFaxrWirzitA5rQ2HDEdYv8hqIsF6R1xCE9R553URYe8jrMsL6jrwuIKyjyOsUwjqHvA7iPwU5h19yH8QxXcTq2kdYt5DXJ4Q1AHn9RVjDkNczwhqMvFaEFaV5YYQVrmdhhJWnVWGENUGHwghrsqqREZaWMp0Rli7ryAhLnWlehOXBLi++NuPB7us6hGXDqy3CcmLUFmGZcWmLsPxYtEVYlvTbIixX4m0RFkIQljHlpUVY3mTbIiyEICx7mkuLsBCCsCoQXFqEhRCEhRCEhRCEhRCEVYTa63fCQgjCQgjCQgjCQgjCQgjCQgjCQgjCqkPqoyzCQgjCQgjCQgjCQgjCQgjCKkXnjSFhIQRhIQRhIQRhIQRhIQRhVSPyxpCwEIKwEOI/XsiMWp/OmjcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=200x200 at 0x16E8C7629E8>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = img2.resize((64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAABMUlEQVR4nO2ZwRLDIAhEk/7/P9tDOjnESYV1kXWGd26VJ0qVHkdRFEVRFEWxLefwE60100DneKgITLMaHX4jrjVxTKapgUwjZYKPLqLxgb/pisll6wIX8BLkQMgsEBlxRxEyAERDzAZtJbCY5lNBOwNYKPOpYB7iFAd+eYYDwvzXldEh4Cmix3HM7wpPKoQycNNasy+BosCF0UFXwIi0gCUJfAHupW04mq8KPYbry0XUlfO9LvHfxEG8OdC6EmvoNaQPcU+/mttsoQd3KkwZyGpa/eFe08zHFIVFbZU4ch71RJibO8VE6EWGEVhe1piE18dojfBfYt3utBfd3qgXrknmHYFiInHJmTGRELjANITeA9u3Fg/IQUsAQE7AmwQ5AS8lkE0JZKMosP0/NC62F/gCq854HtLj1c8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x16E8C571940>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to predict 2.7235381603240967\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "loaded_model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "x = image.img_to_array(img2)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "images = np.vstack([x])\n",
    "classes = loaded_model.predict_classes(images, batch_size=10)\n",
    "prediction = gesture_list[int(classes)]\n",
    "end = time.time()\n",
    "print(\"Time to predict\",str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
